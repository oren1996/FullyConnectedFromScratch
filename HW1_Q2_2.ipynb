{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6f4f83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "# Hyper Parameters\n",
    "layerDimensions = [784, 128, 64, 2]\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "learningRate = 0.01\n",
    "numberOfLabels = 2\n",
    "sample_size = 128\n",
    "\n",
    "# Image Preprocessing \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "#    ,transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "#                          (0.247, 0.2434, 0.2615)),])\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = dsets.MNIST(root='./data/',\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=transform)\n",
    "\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data/',\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=transform)\n",
    "\n",
    "#train_subset = torch.utils.data.Subset(train_dataset, np.arange(sample_size))\n",
    "train_subset = (train_dataset.data.clone().detach())[:128]\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_subset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=10000,\n",
    "                                          shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752e683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    ### Initialize the neural network\n",
    "    def __init__(self, layerDimensions, epochs, learningRate):\n",
    "        self.accuracy = []\n",
    "        self.layerDimensions = layerDimensions\n",
    "        self.epochs = epochs\n",
    "        self.learningRate = learningRate\n",
    "        self.parameters = {}\n",
    "        self.mean_loss_train = []\n",
    "        self.mean_loss_test = []\n",
    "        ### Initializes randoms weights and biases parameters\n",
    "        L = len(layerDimensions)\n",
    "        for i in range(1, L):\n",
    "            self.parameters['W' + str(i)] = np.random.randn(layerDimensions[i], layerDimensions[i - 1]) * np.sqrt(1.0 / layerDimensions[i])\n",
    "\n",
    "            \n",
    "    ### Activations functions\n",
    "    # 1: Sigmoid Function and his derivative\n",
    "    def sigmoid(self, Z):\n",
    "        return (np.exp(np.dot(-1, Z))) / ((np.exp(np.dot(-1, Z)) + 1) ** 2)\n",
    "\n",
    "    def sigmoidDerivative(self, Z):\n",
    "        return 1 / (1 + np.exp(np.dot(-1, Z)))\n",
    "        \n",
    "    # 2: Relu function and his derivative\n",
    "    def relu(self, Z):\n",
    "        temp = []\n",
    "        for i in Z:\n",
    "            temp.append(max(i, 0))\n",
    "        return np.array(temp)\n",
    "    \n",
    "    def reluDerivative(self, Z):\n",
    "        temp = []\n",
    "        for i in Z:\n",
    "            if i > 0:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        return np.array(temp)\n",
    "\n",
    "    # 3: Softmax function and his derivative\n",
    "    def softmax(self, Z):\n",
    "        exps = np.exp(Z - Z.max())\n",
    "        return exps / np.sum(exps, axis=0)\n",
    "        \n",
    "    def softmaxDerivative(self, Z):\n",
    "        exps = np.exp(Z - Z.max())\n",
    "        return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "\n",
    "    ### Forward propagation\n",
    "    def forwardP(self, X_train):\n",
    "        # Calculate parameters for input layer\n",
    "        self.parameters['A0'] = X_train\n",
    "        \n",
    "        # Calculate parameters for hidden layer 1\n",
    "        self.parameters['Z1'] = np.dot(self.parameters[\"W1\"], self.parameters['A0'])\n",
    "        self.parameters['A1'] = self.relu(self.parameters['Z1'])\n",
    "        \n",
    "        # Calculate parameters for hidden layer 2\n",
    "        self.parameters['Z2'] = np.dot(self.parameters[\"W2\"], self.parameters['A1'])\n",
    "        self.parameters['A2'] = self.relu(self.parameters['Z2'])\n",
    "        \n",
    "        # Calculate parameters for hidden layer 3\n",
    "        self.parameters['Z3'] = np.dot(self.parameters[\"W3\"], self.parameters['A2'])\n",
    "        self.parameters['A3'] = self.softmax(self.parameters['Z3'])\n",
    "        return self.parameters['A3']\n",
    "\n",
    "    \n",
    "    ### Backward propagation\n",
    "    def backwardP(self, labels, y_predict): \n",
    "        changed_w = {}\n",
    "        \n",
    "        # Calculate W3 update\n",
    "        # loss function: Binary Cross Entropy Function\n",
    "        #numberOfLabels = y_predict.shape[0]\n",
    "        #dMst = 2 * (y_predict - y_train) / numberOfLabels\n",
    "        \n",
    "        dBce = -labels/y_predict + (1-labels)/(1-y_predict)\n",
    "        error = dBce * self.softmaxDerivative(self.parameters['Z3'])\n",
    "        changed_w['W3'] = np.outer(error, self.parameters['A2'])\n",
    "\n",
    "        # Calculate W2 update\n",
    "        error = np.dot(self.parameters['W3'].T, error) * self.reluDerivative(self.parameters['Z2'])\n",
    "        changed_w['W2'] = np.outer(error, self.parameters['A1'])\n",
    "\n",
    "        # Calculate W1 update\n",
    "        error = np.dot(self.parameters['W2'].T, error) * self.reluDerivative(self.parameters['Z1'])\n",
    "        changed_w['W1'] = np.outer(error, self.parameters['A0'])\n",
    "\n",
    "        return changed_w\n",
    "\n",
    "    ### Update parameters\n",
    "    def update_parameters(self, gradients):\n",
    "        for key, value in gradients.items():\n",
    "            self.parameters[key] -= self.learningRate * value\n",
    "            \n",
    "\n",
    "    \n",
    "    def crossEntropy(self, y_true, y_pred):\n",
    "        n = len(y_true)\n",
    "        summ = 0\n",
    "        for i in range(n):\n",
    "            summ += (y_true[i]*np.log(y_pred[i])) + (1-y_true[i])*(np.log(1-y_pred[i]))\n",
    "        loss = -summ/n\n",
    "        return loss\n",
    "\n",
    "\n",
    "    ### Train the data\n",
    "    def train(self, train_list, test_list, arrPropabilityTrain, arrPropabilityTest, numberOfLabels):\n",
    "        for i in range(0,self.epochs):\n",
    "            counter = 0\n",
    "            predictions = []\n",
    "            iteration = i +1\n",
    "            print(f'{iteration}/{self.epochs}')\n",
    "            for x in train_list:\n",
    "                X_train = x\n",
    "                y_train = arrPropabilityTrain[counter]\n",
    "                counter += 1\n",
    "                # scale and shift the inputs\n",
    "                inputs = (np.asfarray(X_train) / 255.0 * 0.99) + 0.01\n",
    "                # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "                labels = np.zeros(numberOfLabels) + 0.01\n",
    "                labels[int(y_train)] = 0.99\n",
    "                y_predict = self.forwardP(np.array(inputs).flatten())\n",
    "                pred = y_predict[int(y_train)]\n",
    "                predictions.append(pred)\n",
    "                gradients = self.backwardP(labels, y_predict)\n",
    "                self.update_parameters(gradients)\n",
    "            for i in range(len(predictions)):\n",
    "                if int(arrPropabilityTrain[i]) == 0:\n",
    "                    predictions[i] = 1-predictions[i]\n",
    "            loss_train = self.crossEntropy(arrPropabilityTrain, predictions)\n",
    "            self.mean_loss_train.append(loss_train)\n",
    "            loss_test = self.test(test_list,arrPropabilityTest, numberOfLabels)\n",
    "            self.mean_loss_test.append(loss_test)\n",
    "\n",
    "    # def lossConvergence():\n",
    "    #     epochs = self.epochs\n",
    "    #     lossForEpoch = self.mean_loss\n",
    "    #     print(lossForEpoch)\n",
    "\n",
    "    ### Compute accuracy\n",
    "    def test(self, test_data, arrPropabilityTest, numberOfLabels):\n",
    "        counter = 0\n",
    "        predictions = []\n",
    "        for x in test_data:\n",
    "            X_test, temp = x\n",
    "            y_test = arrPropabilityTest[counter]\n",
    "            counter += 1\n",
    "            inputs = (np.asfarray(X_test) / 255.0 * 0.99) + 0.01\n",
    "            # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "            labels = np.zeros(numberOfLabels) + 0.01\n",
    "            labels[int(y_test)] = 0.99\n",
    "            y_predict = self.forwardP(np.array(inputs).flatten())\n",
    "            pred = y_predict[int(y_test)]\n",
    "            predictions.append(pred)\n",
    "        for i in range(len(predictions)):\n",
    "            if int(arrPropabilityTest[i]) == 0:\n",
    "                predictions[i] = 1 - predictions[i]\n",
    "        loss_test = self.crossEntropy(arrPropabilityTest, predictions)\n",
    "        return loss_test\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb4054e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create an array of 128 labels binary.\n",
    "# Each entry in the array corresponds to an image in the train_subset\n",
    "bernoulli_arr_train = np.random.binomial(n = 1, p = 0.5, size=sample_size)\n",
    "bernoulli_arr_train_float = np.array(bernoulli_arr_train, dtype=float)\n",
    "bernoulli_arr_test = np.random.binomial(n=1, p =0.5, size=len(test_dataset))\n",
    "bernoulli_arr_test_float = np.array(bernoulli_arr_test, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf072b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20\n",
      "2/20\n",
      "3/20\n",
      "4/20\n",
      "5/20\n",
      "6/20\n",
      "7/20\n",
      "8/20\n",
      "9/20\n",
      "10/20\n",
      "11/20\n",
      "12/20\n",
      "13/20\n",
      "14/20\n",
      "15/20\n",
      "16/20\n",
      "17/20\n",
      "18/20\n",
      "19/20\n",
      "20/20\n"
     ]
    }
   ],
   "source": [
    "nn1 = NN(layerDimensions, num_epochs, learningRate)\n",
    "nn1.train(train_subset, test_dataset, bernoulli_arr_train_float,bernoulli_arr_test_float, numberOfLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb52e5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3064636023084122, 0.574917609062323, 0.39766590206695457, 0.27797734708771665, 0.196286447584235, 0.1522901429356072, 0.11449287142532281, 0.09298655919682385, 0.08050648174659396, 0.06652066655883761, 0.05824130077850176, 0.05348860926273458, 0.048672361262369526, 0.043554118685157614, 0.040270174740866756, 0.0396082892819432, 0.034738515805841905, 0.03171790171427236, 0.029176341463682566, 0.027431944898924573]\n",
      "[0.6933915379103136, 0.6932844139390095, 0.6933239449122333, 0.693231233612712, 0.6932365357627542, 0.6932119513149355, 0.6931609150359065, 0.6931331633802934, 0.6931340110585571, 0.6931249143442351, 0.6931226163421578, 0.6931318371344276, 0.6931270274529606, 0.6931375129704778, 0.693139503512477, 0.6931372552584408, 0.6931381967552663, 0.6931397041398156, 0.6931387939936416, 0.693139475332173]\n"
     ]
    }
   ],
   "source": [
    "print(nn1.mean_loss_train)\n",
    "print(nn1.mean_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1cdf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931792272081394"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_loss_value_test = np.mean(nn1.mean_loss_test)\n",
    "mean_loss_value_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e3bfeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# net_and_labels = {'train_labels': bernoulli_arr_train_float, 'test_labels': bernoulli_arr_test_float, 'net':nn1, 'loss':mean_loss_value_test}\n",
    "# pickle.dump(net_and_labels, open('model_q2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb2dc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code for the plots:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(20), nn1.mean_loss_test, c='red')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.plot(range(20), nn1.mean_loss_train, c='blue')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.legend(['test', 'train'])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
